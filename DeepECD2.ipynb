{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25521185-3f64-4cf4-a594-97471ae29014",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def comparison(testlabel, resultslabel):\n",
    "\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    TN = 0\n",
    "    FN = 0\n",
    "\n",
    "    for row1 in range(len(resultslabel)):\n",
    "        if resultslabel[row1] < 0.5:\n",
    "            resultslabel[row1] = 0\n",
    "        else:\n",
    "            resultslabel[row1] = 1\n",
    "\n",
    "    for row2 in range(len(testlabel)):\n",
    "\n",
    "        if testlabel[row2] == 1 and testlabel[row2] == resultslabel[row2]:\n",
    "            TP = TP + 1\n",
    "        if testlabel[row2] == 0 and testlabel[row2] != resultslabel[row2]:\n",
    "            FP = FP + 1\n",
    "        if testlabel[row2] == 0 and testlabel[row2] == resultslabel[row2]:\n",
    "            TN = TN + 1\n",
    "        if testlabel[row2] == 1 and testlabel[row2] != resultslabel[row2]:\n",
    "            FN = FN + 1\n",
    "\n",
    "    # ACC：accuracy\n",
    "    if TP + TN + FP + FN != 0:\n",
    "        ACC = (TP + TN) / (TP + TN + FP + FN)\n",
    "    else:\n",
    "        ACC = 999999\n",
    "\n",
    "    # F1 score：is the harmonic mean of precision and sensitivity\n",
    "    if TP + FP + FN != 0:\n",
    "        F1 = (2 * TP) / (2 * TP + FP + FN)\n",
    "    else:\n",
    "        F1 = 999999\n",
    "\n",
    "    # MCC：Matthews correlation coefficient\n",
    "    if (TP + FP) * (TP + FN) * (TN + FP) * (TN + FN) != 0:\n",
    "        MCC = (TP * TN - FP * FN) / math.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN))\n",
    "    else:\n",
    "        MCC = 999999\n",
    "\n",
    "    return TP, FP, TN, FN, ACC, F1, MCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "714c0d23-083b-4a7a-b4f4-d4b855443a13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 03:55:28.904615: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n",
      "(40544, 500, 5)\n",
      "(4505, 500, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 03:56:18.150671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 23797 MB memory:  -> device: 0, name: Tesla P40, pci bus id: 0000:04:00.0, compute capability: 6.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 03:56:21.800807: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8900\n",
      "2023-09-19 03:56:22.293474: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7f6ce81fe6d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-09-19 03:56:22.293523: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P40, Compute Capability 6.1\n",
      "2023-09-19 03:56:22.301295: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:255] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-09-19 03:56:22.521763: I ./tensorflow/compiler/jit/device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - ETA: 0s - loss: 0.4517 - accuracy: 0.7893"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`1st_input` is not a valid tf.function parameter name. Sanitizing to `arg_1st_input`.\n",
      "WARNING:absl:`1st_input` is not a valid tf.function parameter name. Sanitizing to `arg_1st_input`.\n",
      "WARNING:absl:`1st_input` is not a valid tf.function parameter name. Sanitizing to `arg_1st_input`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 10s 12ms/step - loss: 0.4517 - accuracy: 0.7893 - val_loss: 0.3512 - val_accuracy: 0.8496 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "571/571 [==============================] - ETA: 0s - loss: 0.3213 - accuracy: 0.8672"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`1st_input` is not a valid tf.function parameter name. Sanitizing to `arg_1st_input`.\n",
      "WARNING:absl:`1st_input` is not a valid tf.function parameter name. Sanitizing to `arg_1st_input`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 11ms/step - loss: 0.3213 - accuracy: 0.8672 - val_loss: 0.2732 - val_accuracy: 0.8947 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "566/571 [============================>.] - ETA: 0s - loss: 0.3140 - accuracy: 0.8726INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3138 - accuracy: 0.8726 - val_loss: 0.2695 - val_accuracy: 0.8959 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "571/571 [==============================] - 5s 9ms/step - loss: 0.2952 - accuracy: 0.8825 - val_loss: 0.3086 - val_accuracy: 0.8695 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "566/571 [============================>.] - ETA: 0s - loss: 0.2879 - accuracy: 0.8851INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 11ms/step - loss: 0.2878 - accuracy: 0.8853 - val_loss: 0.2629 - val_accuracy: 0.8994 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "566/571 [============================>.] - ETA: 0s - loss: 0.2818 - accuracy: 0.8893INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 11ms/step - loss: 0.2821 - accuracy: 0.8890 - val_loss: 0.2548 - val_accuracy: 0.9063 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "571/571 [==============================] - 5s 9ms/step - loss: 0.2784 - accuracy: 0.8894 - val_loss: 0.2606 - val_accuracy: 0.8984 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "571/571 [==============================] - 5s 9ms/step - loss: 0.2746 - accuracy: 0.8901 - val_loss: 0.2689 - val_accuracy: 0.8927 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2648 - accuracy: 0.8965 - val_loss: 0.2614 - val_accuracy: 0.8991 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "571/571 [==============================] - 5s 9ms/step - loss: 0.2637 - accuracy: 0.8963 - val_loss: 0.2588 - val_accuracy: 0.8979 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "571/571 [==============================] - 5s 9ms/step - loss: 0.2658 - accuracy: 0.8952 - val_loss: 0.2629 - val_accuracy: 0.8982 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "571/571 [==============================] - 5s 9ms/step - loss: 0.2615 - accuracy: 0.8973 - val_loss: 0.2660 - val_accuracy: 0.8962 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "571/571 [==============================] - 5s 9ms/step - loss: 0.2571 - accuracy: 0.9001 - val_loss: 0.2616 - val_accuracy: 0.8957 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2493 - accuracy: 0.9044 - val_loss: 0.2537 - val_accuracy: 0.8964 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "571/571 [==============================] - 5s 9ms/step - loss: 0.2504 - accuracy: 0.9023 - val_loss: 0.2653 - val_accuracy: 0.8957 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "571/571 [==============================] - 5s 9ms/step - loss: 0.2517 - accuracy: 0.9005 - val_loss: 0.2705 - val_accuracy: 0.8967 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2456 - accuracy: 0.9045 - val_loss: 0.2534 - val_accuracy: 0.8984 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "571/571 [==============================] - 5s 9ms/step - loss: 0.2478 - accuracy: 0.9037 - val_loss: 0.2895 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2441 - accuracy: 0.9050 - val_loss: 0.2848 - val_accuracy: 0.8927 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2438 - accuracy: 0.9052 - val_loss: 0.2862 - val_accuracy: 0.8895 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 03:58:07.900342: W tensorflow/core/util/tensor_slice_reader.cc:97] Could not open ./model/bianma/bestmodel: FAILED_PRECONDITION: model/bianma/bestmodel; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 3ms/step\n",
      "PLeccNET\n",
      "TP: 2223 FP: 283 TN: 1794 FN: 205\n",
      "ACC: 0.8916759156492786 F1: 0.9010944466963924 MCC: 0.7819126230229125\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, MaxPool1D,Bidirectional, GRU,Flatten, Dropout, Conv1D,Reshape,Input,AveragePooling1D,LSTM,Attention,MultiHeadAttention,MaxPooling1D,GlobalMaxPooling1D,Concatenate,BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers,Model,optimizers\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.losses import binary_crossentropy, hinge\n",
    "\n",
    "lu_model = 'bianma'\n",
    "callback4 = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10,\n",
    "                                             verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0),\n",
    "                 callbacks.ModelCheckpoint(filepath=r'./model/'+lu_model+'/bestmodel', monitor='val_accuracy', verbose=0,mode = 'max',\n",
    "                                           save_best_only=True, save_weights_only=False)]\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "f = open('./ecc/arabidopsis/arabidopsis.csv')\n",
    "train_data = []\n",
    "label = []\n",
    "while(True):\n",
    "    tt = f.readline()[:-1]\n",
    "    if(len(tt) <= 1):\n",
    "        break\n",
    "    tt = tt.split(',')\n",
    "    dd = []\n",
    "    for j in tt[0].upper():\n",
    "        if(j == 'A'):\n",
    "            dd.append([0,0,0,0,1])\n",
    "        elif (j == 'T'):\n",
    "            dd.append([0,0,0,1,0])\n",
    "        elif (j == 'G'):\n",
    "            dd.append([0,0,1,0,0])\n",
    "        elif (j == 'C'):\n",
    "            dd.append([0,1,0,0,0])\n",
    "        else:\n",
    "            dd.append([0,0,0,0,0])\n",
    "    while(len(dd) < 500):\n",
    "        dd.append([0,0,0,0,0])\n",
    "    train_data.append(dd)\n",
    "\n",
    "    label.append(int(tt[1]))\n",
    "\n",
    "\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data,test_data,label,test_label=train_test_split(train_data,label,test_size=0.1,random_state=3753,stratify=label)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_label = np.array(test_label)\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "\n",
    "inputs1 = Input(shape=(500,5),name='1st_input')\n",
    "\n",
    "x_mod = Conv1D(128,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(inputs1)\n",
    "\n",
    "x_mod = Conv1D(64,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(x_mod)\n",
    "\n",
    "x_mod = MaxPooling1D(2)(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "\n",
    "x_mod = Flatten()(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "x_mod = Dense(64, activation='sigmoid')(x_mod)\n",
    "out = Dense(1, activation='sigmoid')(x_mod)\n",
    "\n",
    "CNN_model = Model(inputs=[inputs1], outputs=[out])#合成模型\n",
    "\n",
    "\n",
    "# 自定义损失函数\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # 交叉熵损失\n",
    "    cross_entropy_loss = binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Hinge Cross-Entropy Loss\n",
    "    # hinge_loss = tf.losses.hinge(y_true, y_pred)\n",
    "    \n",
    "    # 将两个损失相加\n",
    "    total_loss = cross_entropy_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CNN_model.compile(loss=custom_loss,\n",
    "              optimizer=optimizers.Adam(learning_rate=0.001,beta_1=0.9, beta_2=0.888, epsilon=1e-08),metrics=['accuracy'],\n",
    "              )\n",
    "\n",
    "\n",
    "\n",
    "CNN_history = CNN_model.fit(train_data,\n",
    "                          label,\n",
    "                          validation_split=0.1,\n",
    "                          epochs=20,\n",
    "                          batch_size=64,\n",
    "                          verbose=1,\n",
    "                          shuffle=True,\n",
    "                          callbacks = callback4)\n",
    "\n",
    "\n",
    "CNN_model.load_weights('./model/'+lu_model+'/bestmodel')\n",
    "result = open('./arabidopsis_roc_data','a')\n",
    "pl = CNN_model.predict(test_data)\n",
    "re = []\n",
    "for i in range(len(pl)):\n",
    "    re.append(round(pl[i][0],4))\n",
    "\n",
    "re = list(map(lambda x: str(x), re))\n",
    "re = 'p_CNN_model'+','+','.join(re)\n",
    "# print(re)\n",
    "result.write(re+'\\n')\n",
    "test_re = list(map(lambda x: str(x), test_label))\n",
    "test_re = 'test_CNN_model'+','+','.join(test_re)\n",
    "# print(test_re)\n",
    "\n",
    "result.write(test_re+'\\n')\n",
    "\n",
    "result.close()\n",
    "p_test_label = []\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pl)):\n",
    "    if(pl[i] >= 0.5):\n",
    "        p_test_label.append(1)\n",
    "    else:\n",
    "        p_test_label.append(0)\n",
    "# print(p_test_label)\n",
    "TP, FP, TN, FN, ACC, F1, MCC = comparison(p_test_label, test_label)\n",
    "print('PLeccNET')\n",
    "print('TP:', TP, 'FP:', FP, 'TN:', TN, 'FN:', FN)\n",
    "print('ACC:', ACC, 'F1:', F1, 'MCC:', MCC) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb96d862-0e4b-444f-81ba-710007144bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40544, 500, 4)\n",
      "(4505, 500, 4)\n",
      "Epoch 1/20\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.5193 - accuracy: 0.7240INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 8s 11ms/step - loss: 0.5189 - accuracy: 0.7244 - val_loss: 0.3330 - val_accuracy: 0.8691 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3501 - accuracy: 0.8490 - val_loss: 0.3380 - val_accuracy: 0.8560 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "565/571 [============================>.] - ETA: 0s - loss: 0.3208 - accuracy: 0.8671INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3206 - accuracy: 0.8671 - val_loss: 0.2862 - val_accuracy: 0.8890 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "569/571 [============================>.] - ETA: 0s - loss: 0.3084 - accuracy: 0.8721INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3083 - accuracy: 0.8722 - val_loss: 0.2741 - val_accuracy: 0.8984 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3018 - accuracy: 0.8774 - val_loss: 0.2710 - val_accuracy: 0.8940 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2956 - accuracy: 0.8819 - val_loss: 0.2679 - val_accuracy: 0.8962 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2926 - accuracy: 0.8804 - val_loss: 0.2934 - val_accuracy: 0.8819 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2906 - accuracy: 0.8841 - val_loss: 0.2709 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "567/571 [============================>.] - ETA: 0s - loss: 0.2829 - accuracy: 0.8866INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.2830 - accuracy: 0.8865 - val_loss: 0.2570 - val_accuracy: 0.9016 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.2867 - accuracy: 0.8844INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.2867 - accuracy: 0.8843 - val_loss: 0.2577 - val_accuracy: 0.9021 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "570/571 [============================>.] - ETA: 0s - loss: 0.2834 - accuracy: 0.8851INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.2834 - accuracy: 0.8851 - val_loss: 0.2557 - val_accuracy: 0.9028 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "571/571 [==============================] - 5s 9ms/step - loss: 0.2840 - accuracy: 0.8855 - val_loss: 0.2655 - val_accuracy: 0.8989 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2823 - accuracy: 0.8868 - val_loss: 0.2548 - val_accuracy: 0.9023 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "571/571 [==============================] - 5s 9ms/step - loss: 0.2709 - accuracy: 0.8927 - val_loss: 0.2524 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.2735 - accuracy: 0.8922INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.2733 - accuracy: 0.8924 - val_loss: 0.2504 - val_accuracy: 0.9051 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "571/571 [==============================] - 5s 9ms/step - loss: 0.2703 - accuracy: 0.8917 - val_loss: 0.2599 - val_accuracy: 0.8979 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2664 - accuracy: 0.8920 - val_loss: 0.2485 - val_accuracy: 0.9023 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2664 - accuracy: 0.8941 - val_loss: 0.2537 - val_accuracy: 0.8996 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2678 - accuracy: 0.8945 - val_loss: 0.3303 - val_accuracy: 0.8565 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2643 - accuracy: 0.8941 - val_loss: 0.2687 - val_accuracy: 0.8922 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 04:14:14.311070: W tensorflow/core/util/tensor_slice_reader.cc:97] Could not open ./model/bianma/bestmodel: FAILED_PRECONDITION: model/bianma/bestmodel; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 3ms/step\n",
      "PLeccNET\n",
      "TP: 2235 FP: 271 TN: 1786 FN: 213\n",
      "ACC: 0.8925638179800222 F1: 0.9023011707710941 MCC: 0.7832729659551647\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, MaxPool1D,Bidirectional, GRU,Flatten, Dropout, Conv1D,Reshape,Input,AveragePooling1D,LSTM,Attention,MultiHeadAttention,MaxPooling1D,GlobalMaxPooling1D,Concatenate,BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers,Model,optimizers\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.losses import binary_crossentropy, hinge\n",
    "\n",
    "lu_model = 'bianma'\n",
    "callback4 = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10,\n",
    "                                             verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0),\n",
    "                 callbacks.ModelCheckpoint(filepath=r'./model/'+lu_model+'/bestmodel', monitor='val_accuracy', verbose=0,mode = 'max',\n",
    "                                           save_best_only=True, save_weights_only=False)]\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "f = open('./ecc/arabidopsis/arabidopsis.csv')\n",
    "train_data = []\n",
    "label = []\n",
    "while(True):\n",
    "    tt = f.readline()[:-1]\n",
    "    if(len(tt) <= 1):\n",
    "        break\n",
    "    tt = tt.split(',')\n",
    "    dd = []\n",
    "    for j in tt[0].upper():\n",
    "        if(j == 'A'):\n",
    "            dd.append([0,0,0,1])\n",
    "        elif (j == 'T'):\n",
    "            dd.append([0,0,1,0])\n",
    "        elif (j == 'G'):\n",
    "            dd.append([0,0,1,1])\n",
    "        elif (j == 'C'):\n",
    "            dd.append([0,1,0,0])\n",
    "        else:\n",
    "            dd.append([0,0,0,0])\n",
    "    while(len(dd) < 500):\n",
    "        dd.append([0,0,0,0])\n",
    "    train_data.append(dd)\n",
    "\n",
    "    label.append(int(tt[1]))\n",
    "\n",
    "\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data,test_data,label,test_label=train_test_split(train_data,label,test_size=0.1,random_state=3753,stratify=label)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_label = np.array(test_label)\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "\n",
    "inputs1 = Input(shape=(500,4),name='1st_input')\n",
    "\n",
    "x_mod = Conv1D(128,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(inputs1)\n",
    "\n",
    "x_mod = Conv1D(64,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(x_mod)\n",
    "\n",
    "x_mod = MaxPooling1D(2)(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "\n",
    "x_mod = Flatten()(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "x_mod = Dense(64, activation='sigmoid')(x_mod)\n",
    "out = Dense(1, activation='sigmoid')(x_mod)\n",
    "\n",
    "CNN_model = Model(inputs=[inputs1], outputs=[out])#合成模型\n",
    "\n",
    "\n",
    "# 自定义损失函数\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # 交叉熵损失\n",
    "    cross_entropy_loss = binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Hinge Cross-Entropy Loss\n",
    "    # hinge_loss = tf.losses.hinge(y_true, y_pred)\n",
    "    \n",
    "    # 将两个损失相加\n",
    "    total_loss = cross_entropy_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CNN_model.compile(loss=custom_loss,\n",
    "              optimizer=optimizers.Adam(learning_rate=0.001,beta_1=0.9, beta_2=0.888, epsilon=1e-08),metrics=['accuracy'],\n",
    "              )\n",
    "\n",
    "\n",
    "\n",
    "CNN_history = CNN_model.fit(train_data,\n",
    "                          label,\n",
    "                          validation_split=0.1,\n",
    "                          epochs=20,\n",
    "                          batch_size=64,\n",
    "                          verbose=1,\n",
    "                          shuffle=True,\n",
    "                          callbacks = callback4)\n",
    "\n",
    "\n",
    "CNN_model.load_weights('./model/'+lu_model+'/bestmodel')\n",
    "result = open('./arabidopsis_roc_data','a')\n",
    "pl = CNN_model.predict(test_data)\n",
    "re = []\n",
    "for i in range(len(pl)):\n",
    "    re.append(round(pl[i][0],4))\n",
    "\n",
    "re = list(map(lambda x: str(x), re))\n",
    "re = 'p_CNN_model'+','+','.join(re)\n",
    "# print(re)\n",
    "result.write(re+'\\n')\n",
    "test_re = list(map(lambda x: str(x), test_label))\n",
    "test_re = 'test_CNN_model'+','+','.join(test_re)\n",
    "# print(test_re)\n",
    "\n",
    "result.write(test_re+'\\n')\n",
    "\n",
    "result.close()\n",
    "p_test_label = []\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pl)):\n",
    "    if(pl[i] >= 0.5):\n",
    "        p_test_label.append(1)\n",
    "    else:\n",
    "        p_test_label.append(0)\n",
    "# print(p_test_label)\n",
    "TP, FP, TN, FN, ACC, F1, MCC = comparison(p_test_label, test_label)\n",
    "print('PLeccNET')\n",
    "print('TP:', TP, 'FP:', FP, 'TN:', TN, 'FN:', FN)\n",
    "print('ACC:', ACC, 'F1:', F1, 'MCC:', MCC) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8bd48b7-245d-458b-963e-f0ff603218e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40544, 500, 3)\n",
      "(4505, 500, 3)\n",
      "Epoch 1/20\n",
      "571/571 [==============================] - ETA: 0s - loss: 0.4715 - accuracy: 0.7639INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 8s 11ms/step - loss: 0.4715 - accuracy: 0.7639 - val_loss: 0.3125 - val_accuracy: 0.8727 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "566/571 [============================>.] - ETA: 0s - loss: 0.3143 - accuracy: 0.8719INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3140 - accuracy: 0.8720 - val_loss: 0.2665 - val_accuracy: 0.8964 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3079 - accuracy: 0.8754 - val_loss: 0.3109 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2903 - accuracy: 0.8856 - val_loss: 0.2685 - val_accuracy: 0.8949 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "567/571 [============================>.] - ETA: 0s - loss: 0.2845 - accuracy: 0.8879INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.2840 - accuracy: 0.8881 - val_loss: 0.2531 - val_accuracy: 0.9011 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "565/571 [============================>.] - ETA: 0s - loss: 0.2806 - accuracy: 0.8891INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.2811 - accuracy: 0.8887 - val_loss: 0.2499 - val_accuracy: 0.9058 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2773 - accuracy: 0.8908 - val_loss: 0.2821 - val_accuracy: 0.8910 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "571/571 [==============================] - 5s 9ms/step - loss: 0.2773 - accuracy: 0.8906 - val_loss: 0.2536 - val_accuracy: 0.9048 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2711 - accuracy: 0.8944 - val_loss: 0.3222 - val_accuracy: 0.8654 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2696 - accuracy: 0.8959 - val_loss: 0.2776 - val_accuracy: 0.8885 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2635 - accuracy: 0.8979 - val_loss: 0.2600 - val_accuracy: 0.8979 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2627 - accuracy: 0.8991 - val_loss: 0.2642 - val_accuracy: 0.8932 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2638 - accuracy: 0.8962 - val_loss: 0.2599 - val_accuracy: 0.9023 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2556 - accuracy: 0.9025 - val_loss: 0.2720 - val_accuracy: 0.8977 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2578 - accuracy: 0.9010 - val_loss: 0.2593 - val_accuracy: 0.8991 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2592 - accuracy: 0.8988 - val_loss: 0.2920 - val_accuracy: 0.8779 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2283 - accuracy: 0.9145 - val_loss: 0.2550 - val_accuracy: 0.9031 - lr: 1.0000e-04\n",
      "Epoch 18/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2264 - accuracy: 0.9153 - val_loss: 0.2505 - val_accuracy: 0.9026 - lr: 1.0000e-04\n",
      "Epoch 19/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2244 - accuracy: 0.9151 - val_loss: 0.2523 - val_accuracy: 0.9041 - lr: 1.0000e-04\n",
      "Epoch 20/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2225 - accuracy: 0.9164 - val_loss: 0.2498 - val_accuracy: 0.9046 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 04:33:41.889218: W tensorflow/core/util/tensor_slice_reader.cc:97] Could not open ./model/bianma/bestmodel: FAILED_PRECONDITION: model/bianma/bestmodel; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 3ms/step\n",
      "PLeccNET\n",
      "TP: 2232 FP: 274 TN: 1779 FN: 220\n",
      "ACC: 0.8903440621531632 F1: 0.9003630496167809 MCC: 0.7787084316430557\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, MaxPool1D,Bidirectional, GRU,Flatten, Dropout, Conv1D,Reshape,Input,AveragePooling1D,LSTM,Attention,MultiHeadAttention,MaxPooling1D,GlobalMaxPooling1D,Concatenate,BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers,Model,optimizers\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.losses import binary_crossentropy, hinge\n",
    "\n",
    "lu_model = 'bianma'\n",
    "callback4 = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10,\n",
    "                                             verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0),\n",
    "                 callbacks.ModelCheckpoint(filepath=r'./model/'+lu_model+'/bestmodel', monitor='val_accuracy', verbose=0,mode = 'max',\n",
    "                                           save_best_only=True, save_weights_only=False)]\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "f = open('./ecc/arabidopsis/arabidopsis.csv')\n",
    "train_data = []\n",
    "label = []\n",
    "while(True):\n",
    "    tt = f.readline()[:-1]\n",
    "    if(len(tt) <= 1):\n",
    "        break\n",
    "    tt = tt.split(',')\n",
    "    dd = []\n",
    "    for j in tt[0].upper():\n",
    "        if(j == 'A'):\n",
    "            dd.append([0,0,1])\n",
    "        elif (j == 'T'):\n",
    "            dd.append([0,1,0])\n",
    "        elif (j == 'G'):\n",
    "            dd.append([1,0,0])\n",
    "        elif (j == 'C'):\n",
    "            dd.append([-1,-1,-1])\n",
    "        else:\n",
    "            dd.append([0,0,0])\n",
    "    while(len(dd) < 500):\n",
    "        dd.append([0,0,0])\n",
    "    train_data.append(dd)\n",
    "\n",
    "    label.append(int(tt[1]))\n",
    "\n",
    "\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data,test_data,label,test_label=train_test_split(train_data,label,test_size=0.1,random_state=3753,stratify=label)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_label = np.array(test_label)\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "\n",
    "inputs1 = Input(shape=(500,3),name='1st_input')\n",
    "\n",
    "x_mod = Conv1D(128,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(inputs1)\n",
    "\n",
    "x_mod = Conv1D(64,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(x_mod)\n",
    "\n",
    "x_mod = MaxPooling1D(2)(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "\n",
    "x_mod = Flatten()(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "x_mod = Dense(64, activation='sigmoid')(x_mod)\n",
    "out = Dense(1, activation='sigmoid')(x_mod)\n",
    "\n",
    "CNN_model = Model(inputs=[inputs1], outputs=[out])#合成模型\n",
    "\n",
    "\n",
    "# 自定义损失函数\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # 交叉熵损失\n",
    "    cross_entropy_loss = binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Hinge Cross-Entropy Loss\n",
    "    # hinge_loss = tf.losses.hinge(y_true, y_pred)\n",
    "    \n",
    "    # 将两个损失相加\n",
    "    total_loss = cross_entropy_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CNN_model.compile(loss=custom_loss,\n",
    "              optimizer=optimizers.Adam(learning_rate=0.001,beta_1=0.9, beta_2=0.888, epsilon=1e-08),metrics=['accuracy'],\n",
    "              )\n",
    "\n",
    "\n",
    "\n",
    "CNN_history = CNN_model.fit(train_data,\n",
    "                          label,\n",
    "                          validation_split=0.1,\n",
    "                          epochs=20,\n",
    "                          batch_size=64,\n",
    "                          verbose=1,\n",
    "                          shuffle=True,\n",
    "                          callbacks = callback4)\n",
    "\n",
    "\n",
    "CNN_model.load_weights('./model/'+lu_model+'/bestmodel')\n",
    "result = open('./arabidopsis_roc_data','a')\n",
    "pl = CNN_model.predict(test_data)\n",
    "re = []\n",
    "for i in range(len(pl)):\n",
    "    re.append(round(pl[i][0],4))\n",
    "\n",
    "re = list(map(lambda x: str(x), re))\n",
    "re = 'p_CNN_model'+','+','.join(re)\n",
    "# print(re)\n",
    "result.write(re+'\\n')\n",
    "test_re = list(map(lambda x: str(x), test_label))\n",
    "test_re = 'test_CNN_model'+','+','.join(test_re)\n",
    "# print(test_re)\n",
    "\n",
    "result.write(test_re+'\\n')\n",
    "\n",
    "result.close()\n",
    "p_test_label = []\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pl)):\n",
    "    if(pl[i] >= 0.5):\n",
    "        p_test_label.append(1)\n",
    "    else:\n",
    "        p_test_label.append(0)\n",
    "# print(p_test_label)\n",
    "TP, FP, TN, FN, ACC, F1, MCC = comparison(p_test_label, test_label)\n",
    "print('PLeccNET')\n",
    "print('TP:', TP, 'FP:', FP, 'TN:', TN, 'FN:', FN)\n",
    "print('ACC:', ACC, 'F1:', F1, 'MCC:', MCC) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bca3576-6de8-4ef7-8546-1aaa9d352ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40544, 500, 3)\n",
      "(4505, 500, 3)\n",
      "Epoch 1/20\n",
      "567/571 [============================>.] - ETA: 0s - loss: 0.5084 - accuracy: 0.7421INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 8s 11ms/step - loss: 0.5077 - accuracy: 0.7424 - val_loss: 0.4975 - val_accuracy: 0.7596 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "565/571 [============================>.] - ETA: 0s - loss: 0.3826 - accuracy: 0.8384INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3819 - accuracy: 0.8387 - val_loss: 0.3057 - val_accuracy: 0.8838 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "567/571 [============================>.] - ETA: 0s - loss: 0.3524 - accuracy: 0.8499INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3525 - accuracy: 0.8498 - val_loss: 0.2959 - val_accuracy: 0.8893 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3358 - accuracy: 0.8606 - val_loss: 0.3034 - val_accuracy: 0.8816 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3187 - accuracy: 0.8702 - val_loss: 0.3477 - val_accuracy: 0.8464 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3146 - accuracy: 0.8722 - val_loss: 0.2787 - val_accuracy: 0.8878 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "567/571 [============================>.] - ETA: 0s - loss: 0.3034 - accuracy: 0.8751INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3036 - accuracy: 0.8751 - val_loss: 0.2733 - val_accuracy: 0.8932 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.3064 - accuracy: 0.8733INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3067 - accuracy: 0.8732 - val_loss: 0.2725 - val_accuracy: 0.8952 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2959 - accuracy: 0.8796 - val_loss: 0.3239 - val_accuracy: 0.8651 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2931 - accuracy: 0.8822 - val_loss: 0.3223 - val_accuracy: 0.8607 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2827 - accuracy: 0.8869 - val_loss: 0.2987 - val_accuracy: 0.8710 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2806 - accuracy: 0.8884 - val_loss: 0.3419 - val_accuracy: 0.8491 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2827 - accuracy: 0.8871 - val_loss: 0.2661 - val_accuracy: 0.8925 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2705 - accuracy: 0.8934 - val_loss: 0.3330 - val_accuracy: 0.8654 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2678 - accuracy: 0.8937 - val_loss: 0.3040 - val_accuracy: 0.8703 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2739 - accuracy: 0.8890 - val_loss: 0.2668 - val_accuracy: 0.8875 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2650 - accuracy: 0.8932 - val_loss: 0.2622 - val_accuracy: 0.8912 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2652 - accuracy: 0.8933 - val_loss: 0.2884 - val_accuracy: 0.8811 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2635 - accuracy: 0.8954 - val_loss: 0.3600 - val_accuracy: 0.8589 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2627 - accuracy: 0.8964 - val_loss: 0.3169 - val_accuracy: 0.8747 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 04:36:46.737065: W tensorflow/core/util/tensor_slice_reader.cc:97] Could not open ./model/bianma/bestmodel: FAILED_PRECONDITION: model/bianma/bestmodel; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 3ms/step\n",
      "PLeccNET\n",
      "TP: 2219 FP: 287 TN: 1728 FN: 271\n",
      "ACC: 0.8761376248612652 F1: 0.888310648518815 MCC: 0.7493197566540749\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, MaxPool1D,Bidirectional, GRU,Flatten, Dropout, Conv1D,Reshape,Input,AveragePooling1D,LSTM,Attention,MultiHeadAttention,MaxPooling1D,GlobalMaxPooling1D,Concatenate,BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers,Model,optimizers\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.losses import binary_crossentropy, hinge\n",
    "\n",
    "lu_model = 'bianma'\n",
    "callback4 = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10,\n",
    "                                             verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0),\n",
    "                 callbacks.ModelCheckpoint(filepath=r'./model/'+lu_model+'/bestmodel', monitor='val_accuracy', verbose=0,mode = 'max',\n",
    "                                           save_best_only=True, save_weights_only=False)]\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "f = open('./ecc/arabidopsis/arabidopsis.csv')\n",
    "train_data = []\n",
    "label = []\n",
    "while(True):\n",
    "    tt = f.readline()[:-1]\n",
    "    if(len(tt) <= 1):\n",
    "        break\n",
    "    tt = tt.split(',')\n",
    "    dd = []\n",
    "    for j in tt[0].upper():\n",
    "        if(j == 'A'):\n",
    "            dd.append([0,0,1])\n",
    "        elif (j == 'T'):\n",
    "            dd.append([0,0,2])\n",
    "        elif (j == 'G'):\n",
    "            dd.append([0,1,0])\n",
    "        elif (j == 'C'):\n",
    "            dd.append([0,1,1])\n",
    "        else:\n",
    "            dd.append([0,0,0])\n",
    "    while(len(dd) < 500):\n",
    "        dd.append([0,0,0])\n",
    "    train_data.append(dd)\n",
    "\n",
    "    label.append(int(tt[1]))\n",
    "\n",
    "\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data,test_data,label,test_label=train_test_split(train_data,label,test_size=0.1,random_state=3753,stratify=label)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_label = np.array(test_label)\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "\n",
    "inputs1 = Input(shape=(500,3),name='1st_input')\n",
    "\n",
    "x_mod = Conv1D(128,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(inputs1)\n",
    "\n",
    "x_mod = Conv1D(64,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(x_mod)\n",
    "\n",
    "x_mod = MaxPooling1D(2)(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "\n",
    "x_mod = Flatten()(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "x_mod = Dense(64, activation='sigmoid')(x_mod)\n",
    "out = Dense(1, activation='sigmoid')(x_mod)\n",
    "\n",
    "CNN_model = Model(inputs=[inputs1], outputs=[out])#合成模型\n",
    "\n",
    "\n",
    "# 自定义损失函数\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # 交叉熵损失\n",
    "    cross_entropy_loss = binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Hinge Cross-Entropy Loss\n",
    "    # hinge_loss = tf.losses.hinge(y_true, y_pred)\n",
    "    \n",
    "    # 将两个损失相加\n",
    "    total_loss = cross_entropy_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CNN_model.compile(loss=custom_loss,\n",
    "              optimizer=optimizers.Adam(learning_rate=0.001,beta_1=0.9, beta_2=0.888, epsilon=1e-08),metrics=['accuracy'],\n",
    "              )\n",
    "\n",
    "\n",
    "\n",
    "CNN_history = CNN_model.fit(train_data,\n",
    "                          label,\n",
    "                          validation_split=0.1,\n",
    "                          epochs=20,\n",
    "                          batch_size=64,\n",
    "                          verbose=1,\n",
    "                          shuffle=True,\n",
    "                          callbacks = callback4)\n",
    "\n",
    "\n",
    "CNN_model.load_weights('./model/'+lu_model+'/bestmodel')\n",
    "result = open('./arabidopsis_roc_data','a')\n",
    "pl = CNN_model.predict(test_data)\n",
    "re = []\n",
    "for i in range(len(pl)):\n",
    "    re.append(round(pl[i][0],4))\n",
    "\n",
    "re = list(map(lambda x: str(x), re))\n",
    "re = 'p_CNN_model'+','+','.join(re)\n",
    "# print(re)\n",
    "result.write(re+'\\n')\n",
    "test_re = list(map(lambda x: str(x), test_label))\n",
    "test_re = 'test_CNN_model'+','+','.join(test_re)\n",
    "# print(test_re)\n",
    "\n",
    "result.write(test_re+'\\n')\n",
    "\n",
    "result.close()\n",
    "p_test_label = []\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pl)):\n",
    "    if(pl[i] >= 0.5):\n",
    "        p_test_label.append(1)\n",
    "    else:\n",
    "        p_test_label.append(0)\n",
    "# print(p_test_label)\n",
    "TP, FP, TN, FN, ACC, F1, MCC = comparison(p_test_label, test_label)\n",
    "print('PLeccNET')\n",
    "print('TP:', TP, 'FP:', FP, 'TN:', TN, 'FN:', FN)\n",
    "print('ACC:', ACC, 'F1:', F1, 'MCC:', MCC) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46972970-69f8-4eae-8aab-12658da5691b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40544, 500, 3)\n",
      "(4505, 500, 3)\n",
      "Epoch 1/20\n",
      "566/571 [============================>.] - ETA: 0s - loss: 0.4532 - accuracy: 0.7968INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 8s 11ms/step - loss: 0.4530 - accuracy: 0.7969 - val_loss: 0.3708 - val_accuracy: 0.8439 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "571/571 [==============================] - ETA: 0s - loss: 0.3433 - accuracy: 0.8619INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3433 - accuracy: 0.8619 - val_loss: 0.3087 - val_accuracy: 0.8777 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3284 - accuracy: 0.8681 - val_loss: 0.3625 - val_accuracy: 0.8441 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.3107 - accuracy: 0.8774INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3108 - accuracy: 0.8775 - val_loss: 0.2808 - val_accuracy: 0.8903 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "571/571 [==============================] - ETA: 0s - loss: 0.2961 - accuracy: 0.8835INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.2961 - accuracy: 0.8835 - val_loss: 0.2760 - val_accuracy: 0.8915 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "571/571 [==============================] - 5s 9ms/step - loss: 0.2905 - accuracy: 0.8866 - val_loss: 0.2826 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "569/571 [============================>.] - ETA: 0s - loss: 0.2864 - accuracy: 0.8878INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.2864 - accuracy: 0.8877 - val_loss: 0.2733 - val_accuracy: 0.8959 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "567/571 [============================>.] - ETA: 0s - loss: 0.2776 - accuracy: 0.8907INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.2779 - accuracy: 0.8906 - val_loss: 0.2694 - val_accuracy: 0.8986 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2753 - accuracy: 0.8935 - val_loss: 0.2813 - val_accuracy: 0.8873 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2682 - accuracy: 0.8974 - val_loss: 0.2686 - val_accuracy: 0.8959 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2632 - accuracy: 0.8979 - val_loss: 0.2721 - val_accuracy: 0.8927 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2559 - accuracy: 0.9004 - val_loss: 0.2754 - val_accuracy: 0.8937 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2547 - accuracy: 0.9021 - val_loss: 0.2751 - val_accuracy: 0.8937 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2464 - accuracy: 0.9065 - val_loss: 0.2897 - val_accuracy: 0.8848 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2489 - accuracy: 0.9042 - val_loss: 0.3311 - val_accuracy: 0.8708 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2450 - accuracy: 0.9060 - val_loss: 0.2845 - val_accuracy: 0.8880 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2393 - accuracy: 0.9093 - val_loss: 0.2860 - val_accuracy: 0.8858 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2338 - accuracy: 0.9129 - val_loss: 0.3213 - val_accuracy: 0.8769 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2296 - accuracy: 0.9148 - val_loss: 0.4172 - val_accuracy: 0.8515 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2269 - accuracy: 0.9159 - val_loss: 0.3342 - val_accuracy: 0.8727 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 04:51:22.678738: W tensorflow/core/util/tensor_slice_reader.cc:97] Could not open ./model/bianma/bestmodel: FAILED_PRECONDITION: model/bianma/bestmodel; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 2ms/step\n",
      "PLeccNET\n",
      "TP: 2224 FP: 282 TN: 1738 FN: 261\n",
      "ACC: 0.8794672586015538 F1: 0.8912041675015027 MCC: 0.756134932336595\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, MaxPool1D,Bidirectional, GRU,Flatten, Dropout, Conv1D,Reshape,Input,AveragePooling1D,LSTM,Attention,MultiHeadAttention,MaxPooling1D,GlobalMaxPooling1D,Concatenate,BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers,Model,optimizers\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.losses import binary_crossentropy, hinge\n",
    "\n",
    "lu_model = 'bianma'\n",
    "callback4 = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10,\n",
    "                                             verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0),\n",
    "                 callbacks.ModelCheckpoint(filepath=r'./model/'+lu_model+'/bestmodel', monitor='val_accuracy', verbose=0,mode = 'max',\n",
    "                                           save_best_only=True, save_weights_only=False)]\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "f = open('./ecc/arabidopsis/arabidopsis.csv')\n",
    "train_data = []\n",
    "label = []\n",
    "while(True):\n",
    "    tt = f.readline()[:-1]\n",
    "    if(len(tt) <= 1):\n",
    "        break\n",
    "    tt = tt.split(',')\n",
    "    dd = []\n",
    "    for j in tt[0].upper():\n",
    "        if(j == 'A'):\n",
    "            dd.append([0,0,1])\n",
    "        elif (j == 'T'):\n",
    "            dd.append([0,1,0])\n",
    "        elif (j == 'G'):\n",
    "            dd.append([1,0,0])\n",
    "        elif (j == 'C'):\n",
    "            dd.append([0,0,0])\n",
    "        else:\n",
    "            dd.append([0,0,0])\n",
    "    while(len(dd) < 500):\n",
    "        dd.append([0,0,0])\n",
    "    train_data.append(dd)\n",
    "\n",
    "    label.append(int(tt[1]))\n",
    "\n",
    "\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data,test_data,label,test_label=train_test_split(train_data,label,test_size=0.1,random_state=3753,stratify=label)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_label = np.array(test_label)\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "\n",
    "inputs1 = Input(shape=(500,3),name='1st_input')\n",
    "\n",
    "x_mod = Conv1D(128,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(inputs1)\n",
    "\n",
    "x_mod = Conv1D(64,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(x_mod)\n",
    "\n",
    "x_mod = MaxPooling1D(2)(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "\n",
    "x_mod = Flatten()(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "x_mod = Dense(64, activation='sigmoid')(x_mod)\n",
    "out = Dense(1, activation='sigmoid')(x_mod)\n",
    "\n",
    "CNN_model = Model(inputs=[inputs1], outputs=[out])#合成模型\n",
    "\n",
    "\n",
    "# 自定义损失函数\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # 交叉熵损失\n",
    "    cross_entropy_loss = binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Hinge Cross-Entropy Loss\n",
    "    # hinge_loss = tf.losses.hinge(y_true, y_pred)\n",
    "    \n",
    "    # 将两个损失相加\n",
    "    total_loss = cross_entropy_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CNN_model.compile(loss=custom_loss,\n",
    "              optimizer=optimizers.Adam(learning_rate=0.001,beta_1=0.9, beta_2=0.888, epsilon=1e-08),metrics=['accuracy'],\n",
    "              )\n",
    "\n",
    "\n",
    "\n",
    "CNN_history = CNN_model.fit(train_data,\n",
    "                          label,\n",
    "                          validation_split=0.1,\n",
    "                          epochs=20,\n",
    "                          batch_size=64,\n",
    "                          verbose=1,\n",
    "                          shuffle=True,\n",
    "                          callbacks = callback4)\n",
    "\n",
    "\n",
    "CNN_model.load_weights('./model/'+lu_model+'/bestmodel')\n",
    "result = open('./arabidopsis_roc_data','a')\n",
    "pl = CNN_model.predict(test_data)\n",
    "re = []\n",
    "for i in range(len(pl)):\n",
    "    re.append(round(pl[i][0],4))\n",
    "\n",
    "re = list(map(lambda x: str(x), re))\n",
    "re = 'p_CNN_model'+','+','.join(re)\n",
    "# print(re)\n",
    "result.write(re+'\\n')\n",
    "test_re = list(map(lambda x: str(x), test_label))\n",
    "test_re = 'test_CNN_model'+','+','.join(test_re)\n",
    "# print(test_re)\n",
    "\n",
    "result.write(test_re+'\\n')\n",
    "\n",
    "result.close()\n",
    "p_test_label = []\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pl)):\n",
    "    if(pl[i] >= 0.5):\n",
    "        p_test_label.append(1)\n",
    "    else:\n",
    "        p_test_label.append(0)\n",
    "# print(p_test_label)\n",
    "TP, FP, TN, FN, ACC, F1, MCC = comparison(p_test_label, test_label)\n",
    "print('PLeccNET')\n",
    "print('TP:', TP, 'FP:', FP, 'TN:', TN, 'FN:', FN)\n",
    "print('ACC:', ACC, 'F1:', F1, 'MCC:', MCC) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2e93b0b-428d-4bac-a5e1-c81c79eb6442",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40544, 500, 2)\n",
      "(4505, 500, 2)\n",
      "Epoch 1/20\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.6175 - accuracy: 0.6253INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 9s 11ms/step - loss: 0.6173 - accuracy: 0.6254 - val_loss: 0.5330 - val_accuracy: 0.7255 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.5210 - accuracy: 0.7320INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.5209 - accuracy: 0.7322 - val_loss: 0.4697 - val_accuracy: 0.7800 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "571/571 [==============================] - ETA: 0s - loss: 0.4732 - accuracy: 0.7697INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.4732 - accuracy: 0.7697 - val_loss: 0.4055 - val_accuracy: 0.8264 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.4361 - accuracy: 0.7975 - val_loss: 0.3867 - val_accuracy: 0.8261 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "567/571 [============================>.] - ETA: 0s - loss: 0.3984 - accuracy: 0.8206INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3980 - accuracy: 0.8207 - val_loss: 0.3573 - val_accuracy: 0.8594 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "567/571 [============================>.] - ETA: 0s - loss: 0.3831 - accuracy: 0.8326INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3835 - accuracy: 0.8324 - val_loss: 0.3344 - val_accuracy: 0.8705 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "566/571 [============================>.] - ETA: 0s - loss: 0.3651 - accuracy: 0.8409INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3651 - accuracy: 0.8409 - val_loss: 0.3333 - val_accuracy: 0.8713 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3573 - accuracy: 0.8494 - val_loss: 0.3652 - val_accuracy: 0.8496 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "569/571 [============================>.] - ETA: 0s - loss: 0.3444 - accuracy: 0.8552INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3442 - accuracy: 0.8552 - val_loss: 0.3085 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3406 - accuracy: 0.8578 - val_loss: 0.3062 - val_accuracy: 0.8819 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3334 - accuracy: 0.8604 - val_loss: 0.3036 - val_accuracy: 0.8794 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3299 - accuracy: 0.8622 - val_loss: 0.3000 - val_accuracy: 0.8826 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3224 - accuracy: 0.8673 - val_loss: 0.3115 - val_accuracy: 0.8703 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3183 - accuracy: 0.8689 - val_loss: 0.3830 - val_accuracy: 0.8180 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3234 - accuracy: 0.8674 - val_loss: 0.3644 - val_accuracy: 0.8456 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3189 - accuracy: 0.8697 - val_loss: 0.3095 - val_accuracy: 0.8769 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3139 - accuracy: 0.8714 - val_loss: 0.3041 - val_accuracy: 0.8730 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "571/571 [==============================] - 4s 8ms/step - loss: 0.3118 - accuracy: 0.8720 - val_loss: 0.3260 - val_accuracy: 0.8567 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3075 - accuracy: 0.8732 - val_loss: 0.3136 - val_accuracy: 0.8656 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3045 - accuracy: 0.8753 - val_loss: 0.3260 - val_accuracy: 0.8599 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 04:55:00.433102: W tensorflow/core/util/tensor_slice_reader.cc:97] Could not open ./model/bianma/bestmodel: FAILED_PRECONDITION: model/bianma/bestmodel; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 2ms/step\n",
      "PLeccNET\n",
      "TP: 2161 FP: 345 TN: 1745 FN: 254\n",
      "ACC: 0.8670366259711432 F1: 0.8782767730136151 MCC: 0.7325043711788962\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, MaxPool1D,Bidirectional, GRU,Flatten, Dropout, Conv1D,Reshape,Input,AveragePooling1D,LSTM,Attention,MultiHeadAttention,MaxPooling1D,GlobalMaxPooling1D,Concatenate,BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers,Model,optimizers\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.losses import binary_crossentropy, hinge\n",
    "\n",
    "lu_model = 'bianma'\n",
    "callback4 = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10,\n",
    "                                             verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0),\n",
    "                 callbacks.ModelCheckpoint(filepath=r'./model/'+lu_model+'/bestmodel', monitor='val_accuracy', verbose=0,mode = 'max',\n",
    "                                           save_best_only=True, save_weights_only=False)]\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "f = open('./ecc/arabidopsis/arabidopsis.csv')\n",
    "train_data = []\n",
    "label = []\n",
    "while(True):\n",
    "    tt = f.readline()[:-1]\n",
    "    if(len(tt) <= 1):\n",
    "        break\n",
    "    tt = tt.split(',')\n",
    "    dd = []\n",
    "    for j in tt[0].upper():\n",
    "        if(j == 'A'):\n",
    "            dd.append([0,1])\n",
    "        elif (j == 'T'):\n",
    "            dd.append([0,2])\n",
    "        elif (j == 'G'):\n",
    "            dd.append([0,3])\n",
    "        elif (j == 'C'):\n",
    "            dd.append([0,4])\n",
    "        else:\n",
    "            dd.append([0,0])\n",
    "    while(len(dd) < 500):\n",
    "        dd.append([0,0])\n",
    "    train_data.append(dd)\n",
    "\n",
    "    label.append(int(tt[1]))\n",
    "\n",
    "\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data,test_data,label,test_label=train_test_split(train_data,label,test_size=0.1,random_state=3753,stratify=label)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_label = np.array(test_label)\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "\n",
    "inputs1 = Input(shape=(500,2),name='1st_input')\n",
    "\n",
    "x_mod = Conv1D(128,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(inputs1)\n",
    "\n",
    "x_mod = Conv1D(64,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(x_mod)\n",
    "\n",
    "x_mod = MaxPooling1D(2)(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "\n",
    "x_mod = Flatten()(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "x_mod = Dense(64, activation='sigmoid')(x_mod)\n",
    "out = Dense(1, activation='sigmoid')(x_mod)\n",
    "\n",
    "CNN_model = Model(inputs=[inputs1], outputs=[out])#合成模型\n",
    "\n",
    "\n",
    "# 自定义损失函数\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # 交叉熵损失\n",
    "    cross_entropy_loss = binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Hinge Cross-Entropy Loss\n",
    "    # hinge_loss = tf.losses.hinge(y_true, y_pred)\n",
    "    \n",
    "    # 将两个损失相加\n",
    "    total_loss = cross_entropy_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CNN_model.compile(loss=custom_loss,\n",
    "              optimizer=optimizers.Adam(learning_rate=0.001,beta_1=0.9, beta_2=0.888, epsilon=1e-08),metrics=['accuracy'],\n",
    "              )\n",
    "\n",
    "\n",
    "\n",
    "CNN_history = CNN_model.fit(train_data,\n",
    "                          label,\n",
    "                          validation_split=0.1,\n",
    "                          epochs=20,\n",
    "                          batch_size=64,\n",
    "                          verbose=1,\n",
    "                          shuffle=True,\n",
    "                          callbacks = callback4)\n",
    "\n",
    "\n",
    "CNN_model.load_weights('./model/'+lu_model+'/bestmodel')\n",
    "result = open('./arabidopsis_roc_data','a')\n",
    "pl = CNN_model.predict(test_data)\n",
    "re = []\n",
    "for i in range(len(pl)):\n",
    "    re.append(round(pl[i][0],4))\n",
    "\n",
    "re = list(map(lambda x: str(x), re))\n",
    "re = 'p_CNN_model'+','+','.join(re)\n",
    "# print(re)\n",
    "result.write(re+'\\n')\n",
    "test_re = list(map(lambda x: str(x), test_label))\n",
    "test_re = 'test_CNN_model'+','+','.join(test_re)\n",
    "# print(test_re)\n",
    "\n",
    "result.write(test_re+'\\n')\n",
    "\n",
    "result.close()\n",
    "p_test_label = []\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pl)):\n",
    "    if(pl[i] >= 0.5):\n",
    "        p_test_label.append(1)\n",
    "    else:\n",
    "        p_test_label.append(0)\n",
    "# print(p_test_label)\n",
    "TP, FP, TN, FN, ACC, F1, MCC = comparison(p_test_label, test_label)\n",
    "print('PLeccNET')\n",
    "print('TP:', TP, 'FP:', FP, 'TN:', TN, 'FN:', FN)\n",
    "print('ACC:', ACC, 'F1:', F1, 'MCC:', MCC) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5819e324-acc7-495b-a151-649abff48419",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40544, 500, 1)\n",
      "(4505, 500, 1)\n",
      "Epoch 1/20\n",
      "570/571 [============================>.] - ETA: 0s - loss: 0.5248 - accuracy: 0.7368INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 9s 11ms/step - loss: 0.5248 - accuracy: 0.7368 - val_loss: 0.4142 - val_accuracy: 0.8047 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.4327 - accuracy: 0.7984 - val_loss: 0.4593 - val_accuracy: 0.7716 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.3838 - accuracy: 0.8291INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3838 - accuracy: 0.8291 - val_loss: 0.3281 - val_accuracy: 0.8668 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3553 - accuracy: 0.8493 - val_loss: 0.3315 - val_accuracy: 0.8604 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.3408 - accuracy: 0.8568INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3404 - accuracy: 0.8570 - val_loss: 0.3035 - val_accuracy: 0.8799 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3285 - accuracy: 0.8643 - val_loss: 0.3114 - val_accuracy: 0.8757 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3243 - accuracy: 0.8657 - val_loss: 0.3175 - val_accuracy: 0.8747 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3203 - accuracy: 0.8670 - val_loss: 0.3296 - val_accuracy: 0.8639 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3100 - accuracy: 0.8717 - val_loss: 0.2956 - val_accuracy: 0.8789 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "567/571 [============================>.] - ETA: 0s - loss: 0.3087 - accuracy: 0.8729INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3089 - accuracy: 0.8729 - val_loss: 0.2855 - val_accuracy: 0.8866 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3047 - accuracy: 0.8756 - val_loss: 0.3778 - val_accuracy: 0.8409 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3027 - accuracy: 0.8769 - val_loss: 0.3357 - val_accuracy: 0.8644 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2977 - accuracy: 0.8791 - val_loss: 0.3060 - val_accuracy: 0.8789 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2903 - accuracy: 0.8836 - val_loss: 0.2911 - val_accuracy: 0.8838 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2897 - accuracy: 0.8824 - val_loss: 0.3810 - val_accuracy: 0.8451 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "566/571 [============================>.] - ETA: 0s - loss: 0.2847 - accuracy: 0.8866INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.2849 - accuracy: 0.8865 - val_loss: 0.2868 - val_accuracy: 0.8880 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2764 - accuracy: 0.8895 - val_loss: 0.2930 - val_accuracy: 0.8871 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2796 - accuracy: 0.8891 - val_loss: 0.3821 - val_accuracy: 0.8493 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2728 - accuracy: 0.8913 - val_loss: 0.3270 - val_accuracy: 0.8705 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.2690 - accuracy: 0.8930 - val_loss: 0.3725 - val_accuracy: 0.8592 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 04:58:37.250965: W tensorflow/core/util/tensor_slice_reader.cc:97] Could not open ./model/bianma/bestmodel: FAILED_PRECONDITION: model/bianma/bestmodel; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 2ms/step\n",
      "PLeccNET\n",
      "TP: 2169 FP: 337 TN: 1764 FN: 235\n",
      "ACC: 0.8730299667036626 F1: 0.8835030549898167 MCC: 0.7448989262957463\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, MaxPool1D,Bidirectional, GRU,Flatten, Dropout, Conv1D,Reshape,Input,AveragePooling1D,LSTM,Attention,MultiHeadAttention,MaxPooling1D,GlobalMaxPooling1D,Concatenate,BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers,Model,optimizers\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.losses import binary_crossentropy, hinge\n",
    "\n",
    "lu_model = 'bianma'\n",
    "callback4 = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10,\n",
    "                                             verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0),\n",
    "                 callbacks.ModelCheckpoint(filepath=r'./model/'+lu_model+'/bestmodel', monitor='val_accuracy', verbose=0,mode = 'max',\n",
    "                                           save_best_only=True, save_weights_only=False)]\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "f = open('./ecc/arabidopsis/arabidopsis.csv')\n",
    "train_data = []\n",
    "label = []\n",
    "while(True):\n",
    "    tt = f.readline()[:-1]\n",
    "    if(len(tt) <= 1):\n",
    "        break\n",
    "    tt = tt.split(',')\n",
    "    dd = []\n",
    "    for j in tt[0].upper():\n",
    "        if(j == 'A'):\n",
    "            dd.append([1])\n",
    "        elif (j == 'T'):\n",
    "            dd.append([-1])\n",
    "        elif (j == 'G'):\n",
    "            dd.append([2])\n",
    "        elif (j == 'C'):\n",
    "            dd.append([-2])\n",
    "        else:\n",
    "            dd.append([0])\n",
    "    while(len(dd) < 500):\n",
    "        dd.append([0])\n",
    "    train_data.append(dd)\n",
    "\n",
    "    label.append(int(tt[1]))\n",
    "\n",
    "\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data,test_data,label,test_label=train_test_split(train_data,label,test_size=0.1,random_state=3753,stratify=label)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_label = np.array(test_label)\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "\n",
    "inputs1 = Input(shape=(500,1),name='1st_input')\n",
    "\n",
    "x_mod = Conv1D(128,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(inputs1)\n",
    "\n",
    "x_mod = Conv1D(64,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(x_mod)\n",
    "\n",
    "x_mod = MaxPooling1D(2)(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "\n",
    "x_mod = Flatten()(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "x_mod = Dense(64, activation='sigmoid')(x_mod)\n",
    "out = Dense(1, activation='sigmoid')(x_mod)\n",
    "\n",
    "CNN_model = Model(inputs=[inputs1], outputs=[out])#合成模型\n",
    "\n",
    "\n",
    "# 自定义损失函数\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # 交叉熵损失\n",
    "    cross_entropy_loss = binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Hinge Cross-Entropy Loss\n",
    "    # hinge_loss = tf.losses.hinge(y_true, y_pred)\n",
    "    \n",
    "    # 将两个损失相加\n",
    "    total_loss = cross_entropy_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CNN_model.compile(loss=custom_loss,\n",
    "              optimizer=optimizers.Adam(learning_rate=0.001,beta_1=0.9, beta_2=0.888, epsilon=1e-08),metrics=['accuracy'],\n",
    "              )\n",
    "\n",
    "\n",
    "\n",
    "CNN_history = CNN_model.fit(train_data,\n",
    "                          label,\n",
    "                          validation_split=0.1,\n",
    "                          epochs=20,\n",
    "                          batch_size=64,\n",
    "                          verbose=1,\n",
    "                          shuffle=True,\n",
    "                          callbacks = callback4)\n",
    "\n",
    "\n",
    "CNN_model.load_weights('./model/'+lu_model+'/bestmodel')\n",
    "result = open('./arabidopsis_roc_data','a')\n",
    "pl = CNN_model.predict(test_data)\n",
    "re = []\n",
    "for i in range(len(pl)):\n",
    "    re.append(round(pl[i][0],4))\n",
    "\n",
    "re = list(map(lambda x: str(x), re))\n",
    "re = 'p_CNN_model'+','+','.join(re)\n",
    "# print(re)\n",
    "result.write(re+'\\n')\n",
    "test_re = list(map(lambda x: str(x), test_label))\n",
    "test_re = 'test_CNN_model'+','+','.join(test_re)\n",
    "# print(test_re)\n",
    "\n",
    "result.write(test_re+'\\n')\n",
    "\n",
    "result.close()\n",
    "p_test_label = []\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pl)):\n",
    "    if(pl[i] >= 0.5):\n",
    "        p_test_label.append(1)\n",
    "    else:\n",
    "        p_test_label.append(0)\n",
    "# print(p_test_label)\n",
    "TP, FP, TN, FN, ACC, F1, MCC = comparison(p_test_label, test_label)\n",
    "print('PLeccNET')\n",
    "print('TP:', TP, 'FP:', FP, 'TN:', TN, 'FN:', FN)\n",
    "print('ACC:', ACC, 'F1:', F1, 'MCC:', MCC) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00a76292-1bd2-4f1f-b4b4-76e7a5c54152",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40544, 500, 1)\n",
      "(4505, 500, 1)\n",
      "Epoch 1/20\n",
      "569/571 [============================>.] - ETA: 0s - loss: 0.6136 - accuracy: 0.6279INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 9s 11ms/step - loss: 0.6135 - accuracy: 0.6279 - val_loss: 0.5432 - val_accuracy: 0.6974 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "570/571 [============================>.] - ETA: 0s - loss: 0.5008 - accuracy: 0.7481INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.5008 - accuracy: 0.7481 - val_loss: 0.4281 - val_accuracy: 0.8076 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.4465 - accuracy: 0.7882INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.4462 - accuracy: 0.7884 - val_loss: 0.3877 - val_accuracy: 0.8330 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "571/571 [==============================] - ETA: 0s - loss: 0.4251 - accuracy: 0.8038INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.4251 - accuracy: 0.8038 - val_loss: 0.3768 - val_accuracy: 0.8441 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "569/571 [============================>.] - ETA: 0s - loss: 0.4035 - accuracy: 0.8170INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.4034 - accuracy: 0.8172 - val_loss: 0.3606 - val_accuracy: 0.8508 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.3893 - accuracy: 0.8272INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3897 - accuracy: 0.8270 - val_loss: 0.3470 - val_accuracy: 0.8538 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "570/571 [============================>.] - ETA: 0s - loss: 0.3816 - accuracy: 0.8316INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3816 - accuracy: 0.8316 - val_loss: 0.3383 - val_accuracy: 0.8629 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "564/571 [============================>.] - ETA: 0s - loss: 0.3752 - accuracy: 0.8367INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3753 - accuracy: 0.8366 - val_loss: 0.3345 - val_accuracy: 0.8634 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3594 - accuracy: 0.8443 - val_loss: 0.3439 - val_accuracy: 0.8570 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3628 - accuracy: 0.8429 - val_loss: 0.3540 - val_accuracy: 0.8424 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3538 - accuracy: 0.8467 - val_loss: 0.3477 - val_accuracy: 0.8535 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.3475 - accuracy: 0.8506INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3474 - accuracy: 0.8506 - val_loss: 0.3348 - val_accuracy: 0.8644 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "566/571 [============================>.] - ETA: 0s - loss: 0.3463 - accuracy: 0.8533INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3462 - accuracy: 0.8533 - val_loss: 0.3100 - val_accuracy: 0.8755 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3333 - accuracy: 0.8603 - val_loss: 0.3843 - val_accuracy: 0.8180 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "567/571 [============================>.] - ETA: 0s - loss: 0.3337 - accuracy: 0.8608INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.3337 - accuracy: 0.8608 - val_loss: 0.3033 - val_accuracy: 0.8811 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3330 - accuracy: 0.8587 - val_loss: 0.3102 - val_accuracy: 0.8735 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3325 - accuracy: 0.8599 - val_loss: 0.3512 - val_accuracy: 0.8397 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3269 - accuracy: 0.8643 - val_loss: 0.3087 - val_accuracy: 0.8718 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3215 - accuracy: 0.8672 - val_loss: 0.3163 - val_accuracy: 0.8666 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.3230 - accuracy: 0.8636 - val_loss: 0.3946 - val_accuracy: 0.8160 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 05:11:08.340047: W tensorflow/core/util/tensor_slice_reader.cc:97] Could not open ./model/bianma/bestmodel: FAILED_PRECONDITION: model/bianma/bestmodel; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 2ms/step\n",
      "PLeccNET\n",
      "TP: 2141 FP: 365 TN: 1777 FN: 222\n",
      "ACC: 0.869700332963374 F1: 0.8794413637297186 MCC: 0.7394622074164671\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, MaxPool1D,Bidirectional, GRU,Flatten, Dropout, Conv1D,Reshape,Input,AveragePooling1D,LSTM,Attention,MultiHeadAttention,MaxPooling1D,GlobalMaxPooling1D,Concatenate,BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers,Model,optimizers\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.losses import binary_crossentropy, hinge\n",
    "\n",
    "lu_model = 'bianma'\n",
    "callback4 = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10,\n",
    "                                             verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0),\n",
    "                 callbacks.ModelCheckpoint(filepath=r'./model/'+lu_model+'/bestmodel', monitor='val_accuracy', verbose=0,mode = 'max',\n",
    "                                           save_best_only=True, save_weights_only=False)]\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "f = open('./ecc/arabidopsis/arabidopsis.csv')\n",
    "train_data = []\n",
    "label = []\n",
    "while(True):\n",
    "    tt = f.readline()[:-1]\n",
    "    if(len(tt) <= 1):\n",
    "        break\n",
    "    tt = tt.split(',')\n",
    "    dd = []\n",
    "    for j in tt[0].upper():\n",
    "        if(j == 'A'):\n",
    "            dd.append([1])\n",
    "        elif (j == 'T'):\n",
    "            dd.append([2])\n",
    "        elif (j == 'G'):\n",
    "            dd.append([3])\n",
    "        elif (j == 'C'):\n",
    "            dd.append([4])\n",
    "        else:\n",
    "            dd.append([0])\n",
    "    while(len(dd) < 500):\n",
    "        dd.append([0])\n",
    "    train_data.append(dd)\n",
    "\n",
    "    label.append(int(tt[1]))\n",
    "\n",
    "\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data,test_data,label,test_label=train_test_split(train_data,label,test_size=0.1,random_state=3753,stratify=label)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_label = np.array(test_label)\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "\n",
    "inputs1 = Input(shape=(500,1),name='1st_input')\n",
    "\n",
    "x_mod = Conv1D(128,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(inputs1)\n",
    "\n",
    "x_mod = Conv1D(64,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(x_mod)\n",
    "\n",
    "x_mod = MaxPooling1D(2)(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "\n",
    "x_mod = Flatten()(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "x_mod = Dense(64, activation='sigmoid')(x_mod)\n",
    "out = Dense(1, activation='sigmoid')(x_mod)\n",
    "\n",
    "CNN_model = Model(inputs=[inputs1], outputs=[out])#合成模型\n",
    "\n",
    "\n",
    "# 自定义损失函数\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # 交叉熵损失\n",
    "    cross_entropy_loss = binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Hinge Cross-Entropy Loss\n",
    "    # hinge_loss = tf.losses.hinge(y_true, y_pred)\n",
    "    \n",
    "    # 将两个损失相加\n",
    "    total_loss = cross_entropy_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CNN_model.compile(loss=custom_loss,\n",
    "              optimizer=optimizers.Adam(learning_rate=0.001,beta_1=0.9, beta_2=0.888, epsilon=1e-08),metrics=['accuracy'],\n",
    "              )\n",
    "\n",
    "\n",
    "\n",
    "CNN_history = CNN_model.fit(train_data,\n",
    "                          label,\n",
    "                          validation_split=0.1,\n",
    "                          epochs=20,\n",
    "                          batch_size=64,\n",
    "                          verbose=1,\n",
    "                          shuffle=True,\n",
    "                          callbacks = callback4)\n",
    "\n",
    "\n",
    "CNN_model.load_weights('./model/'+lu_model+'/bestmodel')\n",
    "result = open('./arabidopsis_roc_data','a')\n",
    "pl = CNN_model.predict(test_data)\n",
    "re = []\n",
    "for i in range(len(pl)):\n",
    "    re.append(round(pl[i][0],4))\n",
    "\n",
    "re = list(map(lambda x: str(x), re))\n",
    "re = 'p_CNN_model'+','+','.join(re)\n",
    "# print(re)\n",
    "result.write(re+'\\n')\n",
    "test_re = list(map(lambda x: str(x), test_label))\n",
    "test_re = 'test_CNN_model'+','+','.join(test_re)\n",
    "# print(test_re)\n",
    "\n",
    "result.write(test_re+'\\n')\n",
    "\n",
    "result.close()\n",
    "p_test_label = []\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pl)):\n",
    "    if(pl[i] >= 0.5):\n",
    "        p_test_label.append(1)\n",
    "    else:\n",
    "        p_test_label.append(0)\n",
    "# print(p_test_label)\n",
    "TP, FP, TN, FN, ACC, F1, MCC = comparison(p_test_label, test_label)\n",
    "print('PLeccNET')\n",
    "print('TP:', TP, 'FP:', FP, 'TN:', TN, 'FN:', FN)\n",
    "print('ACC:', ACC, 'F1:', F1, 'MCC:', MCC) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e7f082b-52d3-45d3-ae17-d9b6dea56300",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`epsilon` argument is deprecated and will be removed, use `min_delta` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.0.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).keras_api.metrics.1.count\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40544, 500, 1)\n",
      "(4505, 500, 1)\n",
      "Epoch 1/20\n",
      "567/571 [============================>.] - ETA: 0s - loss: 0.6298 - accuracy: 0.5826INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 8s 11ms/step - loss: 0.6298 - accuracy: 0.5825 - val_loss: 0.6100 - val_accuracy: 0.5891 - lr: 0.0010\n",
      "Epoch 2/20\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.6149 - accuracy: 0.5902INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.6148 - accuracy: 0.5904 - val_loss: 0.6092 - val_accuracy: 0.5965 - lr: 0.0010\n",
      "Epoch 3/20\n",
      "566/571 [============================>.] - ETA: 0s - loss: 0.6130 - accuracy: 0.5933INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.6129 - accuracy: 0.5933 - val_loss: 0.6094 - val_accuracy: 0.5973 - lr: 0.0010\n",
      "Epoch 4/20\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.6116 - accuracy: 0.5952INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.6115 - accuracy: 0.5953 - val_loss: 0.6076 - val_accuracy: 0.6022 - lr: 0.0010\n",
      "Epoch 5/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.6108 - accuracy: 0.5963 - val_loss: 0.6072 - val_accuracy: 0.5948 - lr: 0.0010\n",
      "Epoch 6/20\n",
      "566/571 [============================>.] - ETA: 0s - loss: 0.6093 - accuracy: 0.6016INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.6093 - accuracy: 0.6015 - val_loss: 0.6069 - val_accuracy: 0.6059 - lr: 0.0010\n",
      "Epoch 7/20\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.6077 - accuracy: 0.6043INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.6076 - accuracy: 0.6045 - val_loss: 0.6050 - val_accuracy: 0.6138 - lr: 0.0010\n",
      "Epoch 8/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.6064 - accuracy: 0.6098 - val_loss: 0.6107 - val_accuracy: 0.6094 - lr: 0.0010\n",
      "Epoch 9/20\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.6052 - accuracy: 0.6138INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.6051 - accuracy: 0.6138 - val_loss: 0.6014 - val_accuracy: 0.6163 - lr: 0.0010\n",
      "Epoch 10/20\n",
      "567/571 [============================>.] - ETA: 0s - loss: 0.6039 - accuracy: 0.6151INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.6038 - accuracy: 0.6156 - val_loss: 0.6004 - val_accuracy: 0.6217 - lr: 0.0010\n",
      "Epoch 11/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.6028 - accuracy: 0.6185 - val_loss: 0.6021 - val_accuracy: 0.6195 - lr: 0.0010\n",
      "Epoch 12/20\n",
      "569/571 [============================>.] - ETA: 0s - loss: 0.6019 - accuracy: 0.6161INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.6020 - accuracy: 0.6160 - val_loss: 0.6017 - val_accuracy: 0.6232 - lr: 0.0010\n",
      "Epoch 13/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.6008 - accuracy: 0.6227 - val_loss: 0.6018 - val_accuracy: 0.6217 - lr: 0.0010\n",
      "Epoch 14/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.6002 - accuracy: 0.6207 - val_loss: 0.6005 - val_accuracy: 0.6143 - lr: 0.0010\n",
      "Epoch 15/20\n",
      "566/571 [============================>.] - ETA: 0s - loss: 0.5992 - accuracy: 0.6239INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.5994 - accuracy: 0.6236 - val_loss: 0.5991 - val_accuracy: 0.6249 - lr: 0.0010\n",
      "Epoch 16/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.5990 - accuracy: 0.6247 - val_loss: 0.5998 - val_accuracy: 0.6187 - lr: 0.0010\n",
      "Epoch 17/20\n",
      "568/571 [============================>.] - ETA: 0s - loss: 0.5982 - accuracy: 0.6272INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/bianma/bestmodel/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "571/571 [==============================] - 6s 10ms/step - loss: 0.5981 - accuracy: 0.6274 - val_loss: 0.5993 - val_accuracy: 0.6303 - lr: 0.0010\n",
      "Epoch 18/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.5985 - accuracy: 0.6251 - val_loss: 0.6019 - val_accuracy: 0.6175 - lr: 0.0010\n",
      "Epoch 19/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.5975 - accuracy: 0.6273 - val_loss: 0.5992 - val_accuracy: 0.6195 - lr: 0.0010\n",
      "Epoch 20/20\n",
      "571/571 [==============================] - 5s 8ms/step - loss: 0.5969 - accuracy: 0.6290 - val_loss: 0.6017 - val_accuracy: 0.6224 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-19 05:14:49.090877: W tensorflow/core/util/tensor_slice_reader.cc:97] Could not open ./model/bianma/bestmodel: FAILED_PRECONDITION: model/bianma/bestmodel; Is a directory: perhaps your file is in a different file format and you need to use a different restore operator?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 2ms/step\n",
      "PLeccNET\n",
      "TP: 1474 FP: 1032 TN: 1255 FN: 744\n",
      "ACC: 0.6057713651498335 F1: 0.6240474174428451 MCC: 0.21465517450276503\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, MaxPool1D,Bidirectional, GRU,Flatten, Dropout, Conv1D,Reshape,Input,AveragePooling1D,LSTM,Attention,MultiHeadAttention,MaxPooling1D,GlobalMaxPooling1D,Concatenate,BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from tensorflow.keras import regularizers,Model,optimizers\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.losses import binary_crossentropy, hinge\n",
    "\n",
    "lu_model = 'bianma'\n",
    "callback4 = [callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=10,\n",
    "                                             verbose=0, mode='auto', epsilon=0.0001, cooldown=0, min_lr=0),\n",
    "                 callbacks.ModelCheckpoint(filepath=r'./model/'+lu_model+'/bestmodel', monitor='val_accuracy', verbose=0,mode = 'max',\n",
    "                                           save_best_only=True, save_weights_only=False)]\n",
    "tf.random.set_seed(123)\n",
    "np.random.seed(123)\n",
    "f = open('./ecc/arabidopsis/arabidopsis.csv')\n",
    "train_data = []\n",
    "label = []\n",
    "while(True):\n",
    "    tt = f.readline()[:-1]\n",
    "    if(len(tt) <= 1):\n",
    "        break\n",
    "    tt = tt.split(',')\n",
    "    dd = []\n",
    "    for j in tt[0].upper():\n",
    "        if(j == 'A'):\n",
    "            dd.append([0])\n",
    "        elif (j == 'T'):\n",
    "            dd.append([1])\n",
    "        elif (j == 'G'):\n",
    "            dd.append([1])\n",
    "        elif (j == 'C'):\n",
    "            dd.append([0])\n",
    "        else:\n",
    "            dd.append([0])\n",
    "    while(len(dd) < 500):\n",
    "        dd.append([0])\n",
    "    train_data.append(dd)\n",
    "\n",
    "    label.append(int(tt[1]))\n",
    "\n",
    "\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_data,test_data,label,test_label=train_test_split(train_data,label,test_size=0.1,random_state=3753,stratify=label)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_label = np.array(test_label)\n",
    "train_data = np.array(train_data)\n",
    "label = np.array(label)\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n",
    "\n",
    "\n",
    "inputs1 = Input(shape=(500,1),name='1st_input')\n",
    "\n",
    "x_mod = Conv1D(128,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(inputs1)\n",
    "\n",
    "x_mod = Conv1D(64,4, activation='relu',kernel_regularizer=regularizers.l2(0.001))(x_mod)\n",
    "\n",
    "x_mod = MaxPooling1D(2)(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "\n",
    "x_mod = Flatten()(x_mod)\n",
    "x_mod = Dropout(0.1)(x_mod)\n",
    "x_mod = Dense(64, activation='sigmoid')(x_mod)\n",
    "out = Dense(1, activation='sigmoid')(x_mod)\n",
    "\n",
    "CNN_model = Model(inputs=[inputs1], outputs=[out])#合成模型\n",
    "\n",
    "\n",
    "# 自定义损失函数\n",
    "def custom_loss(y_true, y_pred):\n",
    "    # 交叉熵损失\n",
    "    cross_entropy_loss = binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Hinge Cross-Entropy Loss\n",
    "    # hinge_loss = tf.losses.hinge(y_true, y_pred)\n",
    "    \n",
    "    # 将两个损失相加\n",
    "    total_loss = cross_entropy_loss\n",
    "    \n",
    "    return total_loss\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CNN_model.compile(loss=custom_loss,\n",
    "              optimizer=optimizers.Adam(learning_rate=0.001,beta_1=0.9, beta_2=0.888, epsilon=1e-08),metrics=['accuracy'],\n",
    "              )\n",
    "\n",
    "\n",
    "\n",
    "CNN_history = CNN_model.fit(train_data,\n",
    "                          label,\n",
    "                          validation_split=0.1,\n",
    "                          epochs=20,\n",
    "                          batch_size=64,\n",
    "                          verbose=1,\n",
    "                          shuffle=True,\n",
    "                          callbacks = callback4)\n",
    "\n",
    "\n",
    "CNN_model.load_weights('./model/'+lu_model+'/bestmodel')\n",
    "result = open('./arabidopsis_roc_data','a')\n",
    "pl = CNN_model.predict(test_data)\n",
    "re = []\n",
    "for i in range(len(pl)):\n",
    "    re.append(round(pl[i][0],4))\n",
    "\n",
    "re = list(map(lambda x: str(x), re))\n",
    "re = 'p_CNN_model'+','+','.join(re)\n",
    "# print(re)\n",
    "result.write(re+'\\n')\n",
    "test_re = list(map(lambda x: str(x), test_label))\n",
    "test_re = 'test_CNN_model'+','+','.join(test_re)\n",
    "# print(test_re)\n",
    "\n",
    "result.write(test_re+'\\n')\n",
    "\n",
    "result.close()\n",
    "p_test_label = []\n",
    "\n",
    "count = 0\n",
    "for i in range(len(pl)):\n",
    "    if(pl[i] >= 0.5):\n",
    "        p_test_label.append(1)\n",
    "    else:\n",
    "        p_test_label.append(0)\n",
    "# print(p_test_label)\n",
    "TP, FP, TN, FN, ACC, F1, MCC = comparison(p_test_label, test_label)\n",
    "print('PLeccNET')\n",
    "print('TP:', TP, 'FP:', FP, 'TN:', TN, 'FN:', FN)\n",
    "print('ACC:', ACC, 'F1:', F1, 'MCC:', MCC) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4569f67-8a68-4197-881b-1821973c1a70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a8d9a9-eb2f-464e-b014-2a6d9a882250",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364c3f8b-ec69-4fa6-a78d-900089150cfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c55632-23fe-49a3-ab97-ae21e729b899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cc4e24-8ce4-461f-8f34-4fd2ccc958b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe1a45-f42c-469b-a116-31ddc307ef0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0690cb3a-c3d8-4056-bbc1-be5f61f95840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09940aa-393b-4946-80d9-eca1d540a695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10aac456-84d3-4112-b942-f9a3140bae88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f992ab-c4b7-4b80-8924-b5383f79a737",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
